---
title: "Congressional Districts"
author: "David Kane"
date: "3/9/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(tidyverse)
library(rstanarm)
```

```{r, read_in, warning = FALSE}
# Could not figure out a way to remove the message about duplicate Trump column
# names. There must be a way to do that! In the meantime, will just use
# `warning = FALSE` to make it go away.

x <- read_csv(file = "raw_data/results.csv", 
         skip = 1,
         col_types = cols(CD = col_character(),
                          Incumbent = col_character(),
                          Party = col_character(),
                          Biden = col_double(),
                          Trump = col_double(),
                          Clinton = col_double(),
                          Trump_1 = col_double(),
                          Obama = col_double(),
                          Romney = col_double(),
                          X10 = col_logical(),
                          X11 = col_character())) %>% 
  select(CD, Trump, Biden) %>% 
  mutate(biden_win = ifelse(Biden > Trump, 1, 0))
```


```{r}
# Create sample so that we can understand how we might answer our questions if
# we did not have all the data.

small <- x %>% 
  slice_sample(n = 50)
```



```{r model_fit}
# Fit the model.

fit_1 <- stan_glm(formula = biden_win ~ 1, 
                  data = small,
                  family = binomial,
                  refresh = 0,
                  seed = 2021)
```

There are two kinds of questions we can explore. First, what are "average" or "expected" values? Implicit here is the idea that we are considering so many units that the error terms does not matter. Use `posterior_epred()` for those questions. Second, what are "predicted" values for one or a small number of units. We can't ignore that randomness of life, as represented by error terms, when dealing with these questions. Use `posterior_predict()` in this scenario.

```{r}
# posterior distribution for p
# statistical probability that the hypothesis is true
# What's the average that Biden won out of the 50 samples

posterior_epred(fit_1, newdata =  tibble(constant = 1)) %>% 
  as_tibble()  %>% 
 ggplot(aes(x = `1`)) +
    geom_histogram(aes(y = after_stat(count/sum(count))),
                   bins = 50) + 
    labs(title = "Posterior Probability Distribution",
         subtitle = "Proportion of Biden winning is centered around 0.52",
         x = "Proportion p of Biden winning in all districts in the sample",
         y = "Probability") + 
  
    scale_x_continuous(labels = scales::number_format()) +
    scale_y_continuous(labels = scales::percent_format()) +
    theme_classic()


```

```{r}
posterior_predict(fit_1, 
                  newdata = tibble(constant = rep(1, 20))) %>% 
  as_tibble() %>% 
  mutate(total = rowSums(across(`1`:`20`))) %>% 
  select(total) %>% 
  ggplot(aes(total)) +
    geom_histogram(aes(y = after_stat(count/sum(count))),
                   bins = 50) +
    labs(title = "Posterior Probability Distribution",
         subtitle = "Percentage of Biden won from random 20 samples",
         x = "Number of districts won from 20",
         y = "Probability") + 
    scale_x_continuous(labels = scales::number_format(accuracy = 1)) +
    scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
    theme_classic()

fit_1


```


